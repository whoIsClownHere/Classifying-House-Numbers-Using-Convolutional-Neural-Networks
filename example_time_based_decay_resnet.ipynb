{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNEVVX6ZQAypFGdmGWzWCP6"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"5GaCjCY14mF5"},"outputs":[],"source":["import pandas as pd\n","import numpy as np\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","import tensorflow as tf\n","from tensorflow import keras\n","from tensorflow.keras import layers\n","print(tf.__version__)\n","\n","!mkdir /root/.kaggle/\n","with open(\"/root/.kaggle/kaggle.json\", \"w\") as file:\n","    file.write('{\"username\":\"burindima\",\"key\":\"3dc92a9952274c1e89f2f8a09d84f9c0\"}')\n","!kaggle competitions download -c ml-intensive-of-yandex-academy-2023\n","!unzip ml-intensive-of-yandex-academy-2023.zip \n","\n","train_data = pd.read_pickle('data_train')\n","test_data = pd.read_pickle('data_test')\n","x_test = test_data['images'] / 255.0\n","\n","print(f'Train data keys: {train_data.keys()}')\n","print(f'Test data keys: {test_data.keys()}\\n')\n","print(f'Shape of train images: {train_data[\"images\"].shape}')\n","print(f'Shape of test images: {test_data[\"images\"].shape}\\n')\n","print(f'Unique labels: {set(train_data[\"labels\"])}\\n')\n","print(f'Classes distribution: {pd.Series(train_data[\"labels\"]).value_counts(normalize=True)}')"]},{"cell_type":"code","source":["orig_ds = tf.data.Dataset.from_tensor_slices((train_data['images'], train_data['labels']))\n","test_ds = tf.data.Dataset.from_tensor_slices((test_data['images']))"],"metadata":{"id":"Pu0RpCsW4q5E"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","AUTOTUNE = tf.data.AUTOTUNE\n","IMG_SIZE = 32\n","\n","resize_and_rescale = tf.keras.Sequential([\n","  layers.Resizing(IMG_SIZE, IMG_SIZE),\n","  layers.Rescaling(1./255)\n","])\n","\n","def prepare(ds, shuffle=False, augment=False):\n","  # Resize and rescale all datasets.\n","  ds = ds.map(lambda x, y: (resize_and_rescale(x), y), \n","              num_parallel_calls=AUTOTUNE)\n","\n","  if shuffle:\n","    ds = ds.shuffle(1000)\n","\n","  # Batch all datasets.\n","  ds = ds.batch(batch_size).map(lambda x, y: (x, tf.one_hot(y, depth=10)))\n","\n","  # Use buffered prefetching on all datasets.\n","  return ds.prefetch(buffer_size=AUTOTUNE)\n","\n","def prepare_test(ds):\n","  return ds.map(lambda x: resize_and_rescale(x), \n","              num_parallel_calls=AUTOTUNE)"],"metadata":{"id":"yUtu1-vd4wpf"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["orig_ds = augmented_train_dataset\n","len_orig_ds = len(orig_ds)\n","orig_val_ds, orig_train_ds = orig_ds.take(int(len_orig_ds* 0.15)) , orig_ds.skip(int(len_orig_ds * 0.15))"],"metadata":{"id":"TV9tMVoF41ro"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["full_train_ds = prepare(orig_train_ds, shuffle=True)\n","val_ds = prepare(orig_val_ds)\n","test_ds = prepare_test(test_ds)"],"metadata":{"id":"EE5RCIer43Ok"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["!pip install livelossplot"],"metadata":{"id":"ThJdw__T452q"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from tensorflow.keras import layers\n","\n","#СОЗДАЕМ МОДЕЛЬ \n","input_shape = (32, 26, 3)\n","\n","import tensorflow as tf\n","from tensorflow.keras.datasets import mnist\n","from tensorflow.keras.models import Model\n","from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, BatchNormalization, Activation, Add,Dropout\n","\n","\n","# Определение функции для создания Residual блоков\n","def residual_block(inputs, num_filters, kernel_size, strides):\n","    x = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same')(inputs)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.4)(x)\n","    x = Activation('relu')(x)\n","    x = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n","    x = BatchNormalization()(x)\n","    x = Dropout(0.4)(x)\n","    x = Add()([x, inputs])\n","    x = Activation('relu')(x)\n","    return x\n","\n","# Создание модели ResNet-50 архитектуры\n","inputs = Input(shape=input_shape)\n","x = Conv2D(64, kernel_size=3, strides=1, padding='same')(inputs)\n","x = BatchNormalization()(x)\n","x = Activation('relu')(x)\n","x = residual_block(x, 64, 3, 1)\n","x = residual_block(x, 64, 3, 1)\n","x = residual_block(x, 64, 3, 1)\n","x = Conv2D(128, kernel_size=3, strides=2, padding='same')(x)\n","x = BatchNormalization()(x)\n","x = Dropout(0.4)(x)\n","x = Activation('relu')(x)\n","x = residual_block(x, 128, 3, 1)\n","x = residual_block(x, 128, 3, 1)\n","x = residual_block(x, 128, 3, 1)\n","x = Conv2D(256, kernel_size=3, strides=2, padding='same')(x)\n","x = BatchNormalization()(x)\n","x = Dropout(0.4)(x)\n","x = Activation('relu')(x)\n","x = residual_block(x, 256, 3, 1)\n","x = residual_block(x, 256, 3, 1)\n","x = residual_block(x, 256, 3, 1)\n","x = Flatten()(x)\n","outputs = Dense(10, activation='softmax')(x)\n","model = Model(inputs, outputs)\n","\n","\n","# Компиляция и обучение модели\n","model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"],"metadata":{"id":"FxxiXbCb4726"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["initial_learning_rate = 0.01\n","epochs = 100\n","decay = initial_learning_rate / epochs\n","def lr_time_based_decay(epoch, lr):\n"," return lr * 1 / (1 + decay * epoch)\n"],"metadata":{"id":"A6iioY8b4_G-"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from livelossplot import PlotLossesKeras\n","import time \n","\n","start = time.time()\n","callback_ = tf.keras.callbacks.LearningRateScheduler(lr_time_based_decay, verbose=1) \n","model_history = model.fit(full_train_ds, validation_data=val_ds, epochs=100, callbacks=[PlotLossesKeras(), callback], verbose=False)\n","end = time.time() - start \n","print(\"Время: \"+ str(end) +' секунд')"],"metadata":{"id":"89n0_i445A7w"},"execution_count":null,"outputs":[]}]}