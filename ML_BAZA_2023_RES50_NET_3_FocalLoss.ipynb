{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "**ДЛЯ ТЕХ КТО НА COLAB** ,следующие 2 бокса\n",
        "\n",
        "Шаг 2: Загрузка учетных данных API\n",
        "Чтобы загрузить данные из Kaggle, необходимо пройти аутентификацию в сервисах Kaggle. Для этого понадобится API-токен. Его можно сгенерировать в разделе профиля учетной записи пользователя Kaggle.\n",
        "\n",
        "Сначала перейдите в свой профиль Kaggle:\n",
        "\n",
        "\n",
        "Теперь откройте вкладку “Account” (“Аккаунт”) и опуститесь до раздела “API” (скриншот из профиля Kaggle).\n",
        "\n",
        "Будет загружен файл с именем “kaggle.json”, который содержит имя пользователя и ключ API.\n",
        "\n",
        "Это одноразовый шаг, так что вам не придется генерировать учетные данные всякий раз при загрузке набора данных.\n",
        "\n",
        "https://medium.com/nuances-of-programming/%D0%BA%D0%B0%D0%BA-%D0%B8%D0%BC%D0%BF%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D1%82%D1%8C-%D0%BD%D0%B0%D0%B1%D0%BE%D1%80%D1%8B-%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85-kaggle-%D0%B2-google-colab-51de3fd5a9a8#:~:text=%D0%97%D0%B0%D0%BF%D1%83%D1%81%D1%82%D0%B8%D1%82%D0%B5%20%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%20Google%20Colab%20%D0%B8,%D0%BD%D0%B5%D0%BE%D0%B1%D1%85%D0%BE%D0%B4%D0%B8%D0%BC%D1%8B%D1%85%20%D0%B4%D0%BB%D1%8F%20%D0%B7%D0%B0%D0%B3%D1%80%D1%83%D0%B7%D0%BA%D0%B8%20%D0%BD%D0%B0%D0%B1%D0%BE%D1%80%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85"
      ],
      "metadata": {
        "id": "0lTmGvHfufzq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://medium.com/nuances-of-programming/%D0%BA%D0%B0%D0%BA-%D0%B8%D0%BC%D0%BF%D0%BE%D1%80%D1%82%D0%B8%D1%80%D0%BE%D0%B2%D0%B0%D1%82%D1%8C-%D0%BD%D0%B0%D0%B1%D0%BE%D1%80%D1%8B-%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85-kaggle-%D0%B2-google-colab-51de3fd5a9a8#:~:text=%D0%97%D0%B0%D0%BF%D1%83%D1%81%D1%82%D0%B8%D1%82%D0%B5%20%D0%B1%D0%BB%D0%BE%D0%BA%D0%BD%D0%BE%D1%82%20Google%20Colab%20%D0%B8,%D0%BD%D0%B5%D0%BE%D0%B1%D1%85%D0%BE%D0%B4%D0%B8%D0%BC%D1%8B%D1%85%20%D0%B4%D0%BB%D1%8F%20%D0%B7%D0%B0%D0%B3%D1%80%D1%83%D0%B7%D0%BA%D0%B8%20%D0%BD%D0%B0%D0%B1%D0%BE%D1%80%D0%B0%20%D0%B4%D0%B0%D0%BD%D0%BD%D1%8B%D1%85.\n",
        "# Как импортировать наборы данных Kaggle в Google Colab?\n",
        "# Сделать ШАГ 2 \n",
        "# Также есть Лайфхак 2: Загрузка учетных данных Kaggle из Google Drive , чтобы каждый раз загружать kaggle.json\n",
        "! mkdir ~/.kaggle\n",
        "\n",
        "! cp kaggle.json ~/.kaggle/\n",
        "\n",
        "! chmod 600 ~/.kaggle/kaggle.json\n",
        "\n",
        "! kaggle competitions download ml-intensive-of-yandex-academy-2023 #Но аккаунт должен быть зарегистрирован на соревновании"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YnA108UgMN1s",
        "outputId": "f735e956-82bb-4d3a-e95f-e3ef435408a4"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "mkdir: cannot create directory ‘/root/.kaggle’: File exists\n",
            "Downloading ml-intensive-of-yandex-academy-2023.zip to /content\n",
            " 98% 258M/263M [00:04<00:00, 75.0MB/s]\n",
            "100% 263M/263M [00:04<00:00, 62.0MB/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "https://ru.stackoverflow.com/questions/1061024/%D0%94%D0%BE%D1%81%D1%82%D1%83%D0%BF-%D0%BA-%D0%BF%D0%B0%D0%BF%D0%BA%D0%B0%D0%BC-zip-%D0%B0%D1%80%D1%85%D0%B8%D0%B2%D0%B0-%D0%B2-google-colab"
      ],
      "metadata": {
        "id": "79KlR-sjyTZW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# https://ru.stackoverflow.com/questions/1061024/%D0%94%D0%BE%D1%81%D1%82%D1%83%D0%BF-%D0%BA-%D0%BF%D0%B0%D0%BF%D0%BA%D0%B0%D0%BC-zip-%D0%B0%D1%80%D1%85%D0%B8%D0%B2%D0%B0-%D0%B2-google-colab\n",
        "# Доступ к папкам ZIP-архива в Google Colab\n",
        "import zipfile\n",
        "import os\n",
        "\n",
        "data_r = zipfile.ZipFile('ml-intensive-of-yandex-academy-2023.zip', 'r')\n",
        "data_r.printdir()\n",
        "data_r.extractall()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J6FiBelyNauE",
        "outputId": "5f9b7737-9a82-4ba8-ee3b-091bf8cc2119"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "File Name                                             Modified             Size\n",
            "data_test                                      2023-04-04 08:27:46    307200197\n",
            "data_train                                     2023-04-04 08:28:10    614450277\n",
            "meta                                           2023-04-04 08:29:00           73\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**ОТСЮДА УЖЕ ДЛЯ ВСЕХ**"
      ],
      "metadata": {
        "id": "ZMnupu6V9WcK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# http://cs.mipt.ru/advanced_python/lessons/lab13.html\n",
        "# Теперь в отдельной программе выполним десериализацию. Это уже надо всем делать.\n",
        "import pickle\n",
        "\n",
        "# Data_train\n",
        "with open('data_train', 'rb') as f:\n",
        "    data_train = pickle.load(f)\n",
        "print(data_train)\n",
        "# Data_test\n",
        "with open('data_test', 'rb') as f:\n",
        "    data_test = pickle.load(f)\n",
        "print(data_test)\n"
      ],
      "metadata": {
        "id": "hfLsXwQQsqAH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import train_test_split\n",
        "%matplotlib inline\n",
        "from tensorflow.keras import layers"
      ],
      "metadata": {
        "id": "72hMIaEuw-66"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ДАТАСЕТ\n",
        "x_train_full = data_train['images']\n",
        "y_train_full = data_train['labels']\n",
        "\n",
        "x_test = data_test['images']\n",
        "x_train_full, x_test = x_train_full / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "id": "M_vuK4mHvjzx"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "n_values = 10\n",
        "\n",
        "# YOUR CODE HERE\n",
        "y_train_full_one_hot = tf.one_hot(y_train_full, n_values)\n",
        "# y_test_one_hot = tf.one_hot(test_images, n_values)"
      ],
      "metadata": {
        "id": "ES9YRN-28hbW"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "val_size = 0.1\n",
        "batch_size = 256\n",
        "size = x_train_full.shape[0]\n",
        "\n",
        "x_val, y_val_one_hot = x_train_full[:int(size * 0.1)], y_train_full_one_hot[:int(size * 0.1)]\n",
        "x_train, y_train_one_hot = x_train_full[int(size * 0.1):], y_train_full_one_hot[int(size * 0.1):]\n",
        "\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train_one_hot))\n",
        "train_dataset = train_dataset.shuffle(1024)\n",
        "train_dataset = train_dataset.batch(batch_size)\n",
        "\n",
        "val_dataset = tf.data.Dataset.from_tensor_slices((x_val, y_val_one_hot))\n",
        "val_dataset = val_dataset.shuffle(1024)\n",
        "val_dataset = val_dataset.batch(batch_size)"
      ],
      "metadata": {
        "id": "pLYGv6Rgw3-8"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install livelossplot"
      ],
      "metadata": {
        "id": "lPLDKs5PxXvC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "! pip install segmentation_models"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eb70B4f95P61",
        "outputId": "f7f0ac8e-d7c8-475e-f7be-a72429f9e26b"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting segmentation_models\n",
            "  Downloading segmentation_models-1.0.1-py3-none-any.whl (33 kB)\n",
            "Collecting efficientnet==1.0.0\n",
            "  Downloading efficientnet-1.0.0-py3-none-any.whl (17 kB)\n",
            "Collecting image-classifiers==1.0.0\n",
            "  Downloading image_classifiers-1.0.0-py3-none-any.whl (19 kB)\n",
            "Collecting keras-applications<=1.0.8,>=1.0.7\n",
            "  Downloading Keras_Applications-1.0.8-py3-none-any.whl (50 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.7/50.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: scikit-image in /usr/local/lib/python3.9/dist-packages (from efficientnet==1.0.0->segmentation_models) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.9.1 in /usr/local/lib/python3.9/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (1.22.4)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.9/dist-packages (from keras-applications<=1.0.8,>=1.0.7->segmentation_models) (3.8.0)\n",
            "Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.4.1)\n",
            "Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2.25.1)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (23.0)\n",
            "Requirement already satisfied: pillow!=7.1.0,!=7.1.1,!=8.3.0,>=6.1.0 in /usr/local/lib/python3.9/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (8.4.0)\n",
            "Requirement already satisfied: scipy>=1.4.1 in /usr/local/lib/python3.9/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (1.10.1)\n",
            "Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.9/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (2023.3.21)\n",
            "Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.9/dist-packages (from scikit-image->efficientnet==1.0.0->segmentation_models) (3.1)\n",
            "Installing collected packages: keras-applications, image-classifiers, efficientnet, segmentation_models\n",
            "Successfully installed efficientnet-1.0.0 image-classifiers-1.0.0 keras-applications-1.0.8 segmentation_models-1.0.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import layers\n",
        "from segmentation_models.losses import CategoricalFocalLoss\n",
        "import focal_loss\n",
        "#СОЗДАЕМ МОДЕЛЬ \n",
        "input_shape = x_train.shape[-3:]\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import mnist\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, BatchNormalization, Activation, Add,Dropout\n",
        "\n",
        "\n",
        "# Определение функции для создания Residual блоков\n",
        "def residual_block(inputs, num_filters, kernel_size, strides):\n",
        "    x = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same')(inputs)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Activation('relu')(x)\n",
        "    x = Conv2D(num_filters, kernel_size=kernel_size, strides=strides, padding='same')(x)\n",
        "    x = BatchNormalization()(x)\n",
        "    x = Dropout(0.4)(x)\n",
        "    x = Add()([x, inputs])\n",
        "    x = Activation('relu')(x)\n",
        "    return x\n",
        "\n",
        "# Создание модели ResNet-50 архитектуры\n",
        "inputs = Input(shape=input_shape)\n",
        "x = Conv2D(64, kernel_size=3, strides=1, padding='same')(inputs)\n",
        "x = BatchNormalization()(x)\n",
        "x = Activation('relu')(x)\n",
        "x = residual_block(x, 64, 3, 1)\n",
        "x = residual_block(x, 64, 3, 1)\n",
        "x = residual_block(x, 64, 3, 1)\n",
        "x = Conv2D(128, kernel_size=3, strides=2, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Activation('relu')(x)\n",
        "x = residual_block(x, 128, 3, 1)\n",
        "x = residual_block(x, 128, 3, 1)\n",
        "x = residual_block(x, 128, 3, 1)\n",
        "x = Conv2D(256, kernel_size=3, strides=2, padding='same')(x)\n",
        "x = BatchNormalization()(x)\n",
        "x = Dropout(0.4)(x)\n",
        "x = Activation('relu')(x)\n",
        "x = residual_block(x, 256, 3, 1)\n",
        "x = residual_block(x, 256, 3, 1)\n",
        "x = residual_block(x, 256, 3, 1)\n",
        "x = Flatten()(x)\n",
        "outputs = Dense(10, activation='softmax')(x)\n",
        "model = Model(inputs, outputs)\n",
        "\n",
        "\n",
        "# Компиляция и обучение модели\n",
        "model.compile(optimizer='adam', loss=CategoricalFocalLoss(gamma=2), metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "9kuFOHbCxRzV"
      },
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "G5775nmLxf0D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from livelossplot import PlotLossesKeras\n",
        "import time \n",
        "\n",
        "start = time.time() \n",
        "model_history = model.fit(train_dataset, validation_data=val_dataset, epochs=300, callbacks=[PlotLossesKeras()], verbose=False)\n",
        "end = time.time() - start \n",
        "print(\"Время: \"+ str(end) +' секунд') "
      ],
      "metadata": {
        "id": "_k2WqpMNxiIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.save(\"my_model\")\n"
      ],
      "metadata": {
        "id": "WrZZca9kzxKF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "732d1dd0-beaa-4016-8473-1e0d15d64021"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:absl:Found untraced functions such as _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op, _jit_compiled_convolution_op while saving (showing 5 of 21). These functions will not be directly callable after loading.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np \n",
        "\n",
        "# Приводим в единный массив из двойного (может есть оптимальней)\n",
        "predictions = model.predict(x_test)\n",
        "new_predictions = []\n",
        "for i in predictions:\n",
        "  i = list(i)\n",
        "  max_i = max(i)\n",
        "  index_max_i = i.index(max_i)\n",
        "  new_predictions.append(index_max_i)\n"
      ],
      "metadata": {
        "id": "ayoaJilK3YQY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ce689865-1b68-497b-90d5-9b33774c8db7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "782/782 [==============================] - 8s 11ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd   #  pip install pandas\n",
        "\n",
        "columns=['Id', 'Category']\n",
        "\n",
        "data = []\n",
        "data.append(np.arange(len(new_predictions)))\n",
        "data.append(new_predictions)\n",
        "data = np.array(data).T\n",
        "df = pd.DataFrame(data, columns=columns)\n",
        "df['Id'] = df['Id'].astype(int)\n",
        "\n",
        "df.to_csv('/content/cartridge_accounting_RES50_3-3.csv', index= False )\n"
      ],
      "metadata": {
        "id": "n4D1OOkC5mcQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}